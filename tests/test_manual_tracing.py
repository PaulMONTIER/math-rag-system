#!/usr/bin/env python3
"""
Test pour vÃ©rifier que le traÃ§age manuel Langfuse fonctionne correctement.

Ce test exÃ©cute une vraie requÃªte Ã  travers le workflow et vÃ©rifie:
- La trace principale est crÃ©Ã©e
- Les spans de workflow sont crÃ©Ã©s (classify, plan, retrieve, generate, etc.)
- Les generations OpenAI sont imbriquÃ©es dans les spans
- Tout est correctement finalisÃ© avec outputs et usage
"""

import os
import sys
from dotenv import load_dotenv

load_dotenv()

from src.utils.langfuse_integration import get_langfuse_client, is_langfuse_enabled
from src.workflow.langgraph_pipeline import create_rag_workflow, invoke_workflow
from src.utils.config_loader import load_config

print("=" * 80)
print("TEST TRAÃ‡AGE MANUEL LANGFUSE - WORKFLOW COMPLET")
print("=" * 80)

# VÃ©rifier que Langfuse est activÃ©
if not is_langfuse_enabled():
    print("âŒ Langfuse non activÃ© - configurez les clÃ©s API dans .env")
    print("\nVariables requises:")
    print("  LANGFUSE_PUBLIC_KEY")
    print("  LANGFUSE_SECRET_KEY")
    print("  LANGFUSE_BASE_URL")
    sys.exit(1)

client = get_langfuse_client()
if not client:
    print("âŒ Impossible d'initialiser le client Langfuse")
    sys.exit(1)

print("\nâœ“ Client Langfuse initialisÃ©")

# Charger la config
try:
    config = load_config()
    print("âœ“ Configuration chargÃ©e")
except Exception as e:
    print(f"âŒ Erreur lors du chargement de la config: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# CrÃ©er le workflow
try:
    workflow = create_rag_workflow(config)
    print("âœ“ Workflow MathRAG initialisÃ©")
except Exception as e:
    print(f"âŒ Erreur lors de l'initialisation du workflow: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# Question de test simple
test_question = "Qu'est-ce qu'un espace vectoriel?"

print(f"\nğŸ“ Question de test: '{test_question}'")
print("\nğŸ”„ ExÃ©cution du workflow...")

try:
    # ExÃ©cuter le workflow
    result = invoke_workflow(workflow, test_question)

    print("\nâœ… Workflow exÃ©cutÃ© avec succÃ¨s!")
    print("\n" + "=" * 80)
    print("RÃ‰SULTAT:")
    print("=" * 80)

    # Afficher le rÃ©sultat
    if result.get("generated_answer"):
        print(f"\nğŸ“„ RÃ©ponse gÃ©nÃ©rÃ©e ({len(result['generated_answer'])} caractÃ¨res):")
        print(result["generated_answer"][:200] + "...")

    if result.get("sources_cited"):
        print(f"\nğŸ“š Sources citÃ©es: {len(result['sources_cited'])}")

    if result.get("confidence_score"):
        print(f"\nğŸ¯ Score de confiance: {result['confidence_score']:.2%}")

    # VÃ©rifier les informations Langfuse
    if result.get("langfuse_trace_id"):
        print(f"\nğŸ” Trace Langfuse ID: {result['langfuse_trace_id']}")
        print(f"ğŸ” Trace URL: {os.getenv('LANGFUSE_BASE_URL')}/trace/{result['langfuse_trace_id']}")

    print("\n" + "=" * 80)
    print("VÃ‰RIFICATION LANGFUSE")
    print("=" * 80)

    # Flush pour s'assurer que tout est envoyÃ©
    client.flush()
    print("\nâœ“ DonnÃ©es envoyÃ©es Ã  Langfuse")

    print("\nğŸ“Š Dans votre dashboard Langfuse, vous devriez voir:")
    print("  math_rag_query (trace)")
    print("  â”œâ”€ classify (span)")
    print("  â”‚  â””â”€ openai_call (generation) â† IMBRIQUÃ‰!")
    print("  â”œâ”€ plan (span)")
    print("  â”‚  â””â”€ openai_call (generation) â† IMBRIQUÃ‰!")
    print("  â”œâ”€ retrieve (span)")
    print("  â”œâ”€ generate (span)")
    print("  â”‚  â””â”€ openai_call (generation) â† IMBRIQUÃ‰!")
    print("  â”œâ”€ editor (span)")
    print("  â”‚  â””â”€ openai_call (generation) â† IMBRIQUÃ‰!")
    print("  â””â”€ verify (span)")
    print("     â””â”€ openai_call (generation) â† IMBRIQUÃ‰!")

    print(f"\nğŸŒ Allez sur: {os.getenv('LANGFUSE_BASE_URL')}")
    if result.get("langfuse_trace_id"):
        print(f"ğŸ”— Lien direct: {os.getenv('LANGFUSE_BASE_URL')}/trace/{result['langfuse_trace_id']}")
    else:
        print("Cherchez la trace 'math_rag_query' la plus rÃ©cente")

    print("\n" + "=" * 80)
    print("âœ… TEST TERMINÃ‰ AVEC SUCCÃˆS")
    print("=" * 80)

except Exception as e:
    print(f"\nâŒ Erreur lors de l'exÃ©cution du workflow: {e}")
    import traceback
    traceback.print_exc()

    # Essayer quand mÃªme de flush
    try:
        client.flush()
    except:
        pass

    sys.exit(1)
