# MathRAG - SystÃ¨me RAG Multi-Agent pour MathÃ©matiques

> Un systÃ¨me de Retrieval-Augmented Generation (RAG) intelligent spÃ©cialisÃ© dans les questions mathÃ©matiques, utilisant LangGraph pour orchestrer plusieurs agents IA.

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/LangGraph-latest-green.svg)](https://github.com/langchain-ai/langgraph)
[![Streamlit](https://img.shields.io/badge/Streamlit-latest-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

## Ã€ Propos

MathRAG est un systÃ¨me de question-rÃ©ponse intelligent conÃ§u pour rÃ©pondre Ã  des questions mathÃ©matiques complexes en combinant :

- **Recherche vectorielle** dans une base de documents mathÃ©matiques (PDFs de cours)
- **Recherche web** pour les informations rÃ©centes ou non disponibles localement
- **Orchestration multi-agent** avec LangGraph pour un workflow intelligent
- **ObservabilitÃ© LLM** avec Langfuse pour tracer et optimiser les performances
- **Interface web intuitive** avec Streamlit et support LaTeX

Le systÃ¨me dÃ©cide automatiquement de la meilleure stratÃ©gie (RAG local, web search, ou hybride) en fonction de la question posÃ©e.

## âœ¨ FonctionnalitÃ©s

### Intelligence Multi-Agent

- **Classifier** : DÃ©tecte l'intention de la question (mathÃ©matique, actualitÃ©s, off-topic)
- **Planner** : Choisit la stratÃ©gie optimale (RAG local, web, ou hybride)
- **Retriever** : RÃ©cupÃ¨re les documents pertinents via recherche vectorielle FAISS
- **Web Searcher** : Recherche sur le web pour informations rÃ©centes ou complÃ©mentaires
- **Generator** : GÃ©nÃ¨re une rÃ©ponse dÃ©taillÃ©e avec citations des sources
- **Editor** : RÃ©vise et amÃ©liore la qualitÃ© de la rÃ©ponse
- **Verifier** : VÃ©rifie la complÃ©tude et propose des suggestions de suivi

### Modes d'ExÃ©cution

- **Local** : Utilise Ollama avec modÃ¨les open-source (Mistral, Llama, etc.)
- **Cloud** : Utilise OpenAI GPT-4 / GPT-4-turbo
- **Hybride** : Combine les deux selon les besoins

### ObservabilitÃ© et Monitoring

- **Langfuse** : TraÃ§age complet des appels LLM avec spans hiÃ©rarchiques
- **MÃ©triques** : Tracking des performances, latences, et coÃ»ts
- **Logs structurÃ©s** : SystÃ¨me de logging dÃ©taillÃ© pour debugging

### Interface Utilisateur

- **Interface web Streamlit** avec support LaTeX complet
- **Affichage des sources** avec mÃ©tadonnÃ©es (page, section)
- **Suggestions de questions** de suivi intelligentes
- **Historique** des conversations

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Interface Streamlit                     â”‚
â”‚                    (Port 8501 par dÃ©faut)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LangGraph Workflow                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚Classifierâ”œâ”€â”€â”€â–ºâ”‚ Planner  â”œâ”€â”€â”€â–ºâ”‚ Retriever  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                       â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Verifier â”‚â—„â”€â”€â”¤  Editor  â”‚â—„â”€â”€â”¤ Generator â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                       â”‚                       â”‚
â”‚                                  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚                                  â”‚ Web Searcherâ”‚             â”‚
â”‚                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼               â–¼               â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  FAISS  â”‚    â”‚   LLM    â”‚   â”‚ Langfuse â”‚
   â”‚ Vector  â”‚    â”‚  (Local  â”‚   â”‚  Traces  â”‚
   â”‚  Store  â”‚    â”‚or Cloud) â”‚   â”‚          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Technologies

- **Python 3.11+** : Langage principal
- **LangGraph** : Orchestration du workflow multi-agent
- **LangChain** : Framework pour LLM et RAG
- **FAISS** : Recherche vectorielle haute performance
- **Sentence Transformers** : GÃ©nÃ©ration d'embeddings
- **Streamlit** : Interface web interactive
- **Langfuse** : ObservabilitÃ© et tracing LLM
- **OpenAI API** : GPT-4 / GPT-4-turbo (optionnel)
- **Ollama** : ModÃ¨les locaux open-source (optionnel)

## ğŸ“‹ PrÃ©requis

- Python 3.11 ou supÃ©rieur
- pip (gestionnaire de paquets Python)
- (Optionnel) Ollama installÃ© pour mode local
- (Optionnel) ClÃ©s API OpenAI pour mode cloud
- (Optionnel) ClÃ©s API Langfuse pour observabilitÃ©

## ğŸ“¦ Installation

### 1. Cloner le DÃ©pÃ´t

```bash
git clone https://github.com/PaulMONTIER/math-rag-system.git
cd math-rag-system
```

### 2. CrÃ©er un Environnement Virtuel

```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
```

### 3. Installer les DÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. Configuration

CrÃ©er un fichier `.env` Ã  la racine du projet (copier depuis `.env.example`) :

```bash
# Configuration LLM
LLM_MODE=local  # ou 'cloud' ou 'hybrid'
OPENAI_API_KEY=your_openai_api_key_here  # Si mode cloud

# Configuration Langfuse (optionnel)
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key
LANGFUSE_SECRET_KEY=your_langfuse_secret_key
LANGFUSE_BASE_URL=https://cloud.langfuse.com

# Configuration Google Drive (optionnel)
# Pour tÃ©lÃ©charger les PDFs depuis Google Drive
```

### 5. PrÃ©parer les DonnÃ©es

#### Option A : TÃ©lÃ©charger depuis Google Drive (si configurÃ©)

```bash
# Configurer l'API Google Drive (premiÃ¨re fois uniquement)
python scripts/setup_gdrive.py

# TÃ©lÃ©charger les PDFs
python scripts/download_pdfs.py
```

#### Option B : Ajouter vos PDFs manuellement

Placer vos fichiers PDF dans le dossier `data/raw/`.

### 6. Construire l'Index Vectoriel

```bash
python scripts/build_vector_store.py
```

Cette Ã©tape :
- Extrait le texte des PDFs
- GÃ©nÃ¨re les embeddings
- Construit l'index FAISS
- Peut prendre 10-30 minutes selon le nombre de documents

## ğŸ¯ Utilisation

### Lancer l'Interface Web

```bash
streamlit run src/interface/app.py
```

L'interface sera accessible Ã  : `http://localhost:8501`

### Utilisation Programmatique

```python
from src.workflow.langgraph_pipeline import create_workflow

# CrÃ©er le workflow
app = create_workflow()

# Poser une question
result = app.invoke({
    "question": "Qu'est-ce qu'une intÃ©grale de Riemann ?",
    "chat_history": []
})

print(result["final_answer"])
```

### Mode Local avec Ollama

1. Installer Ollama : https://ollama.ai
2. TÃ©lÃ©charger un modÃ¨le :

```bash
ollama pull mistral
# ou
ollama pull llama3
```

3. Configurer `.env` :

```bash
LLM_MODE=local
```

### Mode Cloud avec OpenAI

Configurer `.env` :

```bash
LLM_MODE=cloud
OPENAI_API_KEY=your_api_key_here
```

## ğŸ“ Structure du Projet

```
math-rag-system/
â”œâ”€â”€ config/                    # Fichiers de configuration
â”‚   â”œâ”€â”€ config.yaml           # Configuration systÃ¨me
â”‚   â””â”€â”€ logging_config.yaml   # Configuration logs
â”‚
â”œâ”€â”€ data/                     # DonnÃ©es et caches
â”‚   â”œâ”€â”€ raw/                  # PDFs sources
â”‚   â”œâ”€â”€ processed/            # Textes extraits
â”‚   â”œâ”€â”€ vector_store/         # Index FAISS
â”‚   â””â”€â”€ logs/                 # Logs d'exÃ©cution
â”‚
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md  # Structure du projet
â”‚   â””â”€â”€ TECHNICAL_DOCUMENTATION.md  # Documentation technique
â”‚
â”œâ”€â”€ scripts/                  # Scripts utilitaires
â”‚   â”œâ”€â”€ build_vector_store.py
â”‚   â”œâ”€â”€ download_pdfs.py
â”‚   â””â”€â”€ setup_gdrive.py
â”‚
â”œâ”€â”€ src/                      # Code source principal
â”‚   â”œâ”€â”€ agents/               # Agents du workflow
â”‚   â”‚   â”œâ”€â”€ classifier.py
â”‚   â”‚   â”œâ”€â”€ planner.py
â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â”œâ”€â”€ generator.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ extraction/           # Extraction PDF
â”‚   â”œâ”€â”€ interface/            # Interface Streamlit
â”‚   â”œâ”€â”€ llm/                  # Clients LLM
â”‚   â”œâ”€â”€ utils/                # Utilitaires
â”‚   â”œâ”€â”€ vectorization/        # SystÃ¨me vectoriel
â”‚   â””â”€â”€ workflow/             # Workflow LangGraph
â”‚
â””â”€â”€ tests/                    # Tests
```

Voir [docs/PROJECT_STRUCTURE.md](docs/PROJECT_STRUCTURE.md) pour plus de dÃ©tails.

## ğŸ§ª Tests

### Tests Unitaires

```bash
# Test rapide du workflow
python tests/test_quick.py

# Test complet avec tracing Langfuse
python tests/test_manual_tracing.py

# Tests de validation
python tests/test_validation.py
```

### Tests d'IntÃ©gration

```bash
# Test du flux complet
python tests/test_complete_flow.py

# Test des questions prÃ©dÃ©finies
python tests/run_test_questions.py
```

## ğŸ“Š Monitoring avec Langfuse

Si Langfuse est configurÃ©, accÃ©dez au dashboard :

1. Ouvrir https://cloud.langfuse.com (ou votre instance self-hosted)
2. Visualiser les traces, spans, et mÃ©triques
3. Analyser les performances et coÃ»ts

Le systÃ¨me trace automatiquement :
- Chaque appel LLM avec input/output
- Latences et token usage
- HiÃ©rarchie des appels (workflow â†’ agents â†’ LLM)
- Scores de qualitÃ© et mÃ©triques custom

## ğŸ“š Documentation

- [README.md](README.md) - Ce fichier
- [QUICKSTART.md](QUICKSTART.md) - Guide de dÃ©marrage rapide
- [docs/PROJECT_STRUCTURE.md](docs/PROJECT_STRUCTURE.md) - Structure du projet
- [docs/TECHNICAL_DOCUMENTATION.md](docs/TECHNICAL_DOCUMENTATION.md) - Documentation technique dÃ©taillÃ©e
- [TESTING.md](TESTING.md) - Guide des tests

## ğŸ› ï¸ DÃ©veloppement

### Installation des DÃ©pendances de DÃ©veloppement

```bash
pip install -r requirements-dev.txt
```

### Linting et Formatage

```bash
# Black pour formatage
black src/ tests/

# Flake8 pour linting
flake8 src/ tests/

# MyPy pour vÃ©rification de types
mypy src/
```

### Visualiser le Graphe LangGraph

```bash
python scripts/utils/visualize_graph.py
```

### Nettoyer les Caches

```bash
# Nettoyer les caches Python
find . -type d -name "__pycache__" -exec rm -rf {} +
find . -name "*.pyc" -delete

# Nettoyer les logs
rm -rf data/logs/*.log

# Reconstruire le vector store
python scripts/build_vector_store.py --force
```

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Voici comment contribuer :

1. Fork le projet
2. CrÃ©er une branche pour votre fonctionnalitÃ© (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

### Guidelines

- Suivre le style de code existant
- Ajouter des tests pour les nouvelles fonctionnalitÃ©s
- Mettre Ã  jour la documentation si nÃ©cessaire
- S'assurer que tous les tests passent avant de soumettre

## ğŸ› Signaler un Bug

Ouvrir une issue sur GitHub avec :
- Description claire du problÃ¨me
- Ã‰tapes pour reproduire
- Comportement attendu vs observÃ©
- Environnement (OS, version Python, etc.)
- Logs pertinents

## ğŸ“ Changelog

### Version 1.0.0 (2024)

- âœ¨ Workflow multi-agent avec LangGraph
- âœ¨ Recherche vectorielle FAISS
- âœ¨ Support Ollama (local) et OpenAI (cloud)
- âœ¨ Interface Streamlit avec LaTeX
- âœ¨ ObservabilitÃ© Langfuse avec spans manuels
- âœ¨ SystÃ¨me de suggestions intelligentes
- âœ¨ Recherche web intÃ©grÃ©e
- âœ¨ Tests unitaires et d'intÃ©gration

## ğŸ“„ License

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ™ Remerciements

- [LangGraph](https://github.com/langchain-ai/langgraph) pour l'orchestration multi-agent
- [FAISS](https://github.com/facebookresearch/faiss) pour la recherche vectorielle
- [Sentence Transformers](https://www.sbert.net/) pour les embeddings
- [Streamlit](https://streamlit.io/) pour l'interface web
- [Langfuse](https://langfuse.com/) pour l'observabilitÃ© LLM
- [Ollama](https://ollama.ai/) pour les modÃ¨les locaux

## ğŸ“§ Contact

Paul MONTIER - [@PaulMONTIER](https://github.com/PaulMONTIER)

Lien du projet : [https://github.com/PaulMONTIER/math-rag-system](https://github.com/PaulMONTIER/math-rag-system)

---

â­ Si ce projet vous est utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile !
